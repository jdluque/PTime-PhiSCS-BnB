{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Task 1**: Compare lower-bound with the actual cost\n",
    "\n",
    "Details of the task:\n",
    "- Set LP using [gurobi](https://www.gurobi.com/features/academic-named-user-license/): Need to set up my license\n",
    "\n",
    "    Using [Google OR-Tools](https://developers.google.com/optimization/lp/lp_example) instead\n",
    "- The lower bound is predicted by the LP objective function\n",
    "- The actual solution from the given data OR with an ILP solver\n",
    "- Reference [here](https://github.com/algo-cancer/PhISCS-BnB) for the data & optimal solution\n",
    "\n",
    "**Questions**:\n",
    "* Why does the input data have question marks? - make it automatically 0\n",
    "* When can a mutation be \"eliminated\" (See the [Read Me Section](https://github.com/algo-cancer/PhISCS-BnB/tree/master?tab=readme-ov-file#output))?\n",
    "\n",
    "\n",
    "### **Task 2**: Does the lower bound increase when adding constraints for non-conflict column pairs to the LP (empiricconflicty tested)\n",
    "\n",
    "Details of the task:\n",
    "- First test with the given data [here](https://github.com/algo-cancer/PhISCS-BnB)\n",
    "- Then test with randomly generated data\n",
    "- Compare lower bound with all pairs vs. only conflict pairs in the LP\n",
    "- Is there 1/2 across the board that is lowering the bound of only conflict LPs?\n",
    "- If the additional constraints don’t help - why?\n",
    "\n",
    "**Questions**:\n",
    "* Should I remove constraints (2), (3), (4), (5), (6)\n",
    "\n",
    "    Effectively remove all variables $B_{p,q,x_1,x_2}$ if $p$ and $q$ don't have a conflict\n",
    "\n",
    "### **Task 3**: Write up proof claiming that once a conflict is resolved, those 2 columns will be <, >, or ≠ in the final solution\n",
    "\n",
    "Look at scratch.txt for additional ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "* `make_random_data(rows, cols, file, bias)` - create random SCS data with a bias\n",
    "* `read_data(file)` - read the data from the file\n",
    "* `get_conversion_cost(X, Y)` - calculate the number of mutations needed to convert X to Y\n",
    "* `find_conflict_columns(X)` - matrix describing if a given pair of columns have a conflict\n",
    "* `solve_LP(SCS, ColSelector = None, verbose = False)` - solve the LP with all pairs or conflict pairs\n",
    "* `compare_SCS(SCS_array, SCS_names)` - compare SCS data among multiples DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "# Input: rows, cols, file, bias\n",
    "# Output: random_data\n",
    "def make_random_data(rows, cols, file=None, bias=0.7):\n",
    "    random_data = [([f'cell{i}'] if file else []) + [int(random.uniform(0, 1) < bias) for j in range(cols)] for i in range(rows)]\n",
    "    random_data = pd.DataFrame(random_data, columns=(['cellIDxmutID'] if file else []) + [f'mut{i}' for i in range(cols)])\n",
    "    if file:\n",
    "        random_data.to_csv(file + \".SC\", index=False, sep='\\t')\n",
    "    return random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data function\n",
    "# Input: file - name of the file without extension\n",
    "# Return: In_SCS, CF_SCS, MutsAtEdges\n",
    "# Note: SCS converts all ? to 0\n",
    "# Note: MutsAtEdges is a list with a tuple - (parent, curr_node, muts: set)\n",
    "find_nodes_re = r\"\\[(?P<parent>[0-9]+)\\]->\\[(?P<node>[0-9]+)\\]:\"\n",
    "def read_data(file):\n",
    "    raw = pd.read_csv(file + \".SC\", sep=\"\\t\", dtype=str)\n",
    "    In_SCS = (raw.iloc[:, 1:] == \"1\").astype(np.bool)\n",
    "    try:\n",
    "        CF_SCS = pd.read_csv(file + \".CFMatrix\", sep=\"\\t\").iloc[:, 1:]\n",
    "    except:\n",
    "        CF_SCS = None\n",
    "    try:\n",
    "        MutsAtEdges = []\n",
    "        with open(file + \".mutsAtEdges\", \"r\") as f:\n",
    "            for line in f:\n",
    "                l = line.strip().split(' ')\n",
    "                parent, curr_node = tuple(map(int, re.match(find_nodes_re, l[0]).groups()))\n",
    "                MutsAtEdges.append((parent, curr_node, set(l[1:])))\n",
    "    except:\n",
    "        MutsAtEdges = None\n",
    "    return In_SCS, CF_SCS, MutsAtEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion cost\n",
    "# Input: X - from matrix, Y - to matrix\n",
    "# Return: Cost of converting X into Y\n",
    "def get_conversion_cost(X, Y):\n",
    "    cost = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if X.iloc[i, j] > Y.iloc[i, j]:\n",
    "                exit(1) # This is a false positive mutation\n",
    "            if X.iloc[i, j] < Y.iloc[i, j]:\n",
    "                cost += 1\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conflict column pairs\n",
    "# Input: X - matrix of SCS data\n",
    "# Return: nxn columns pairs, True - is conflict\n",
    "\n",
    "# Check if a column pair has conflicts - Utility function\n",
    "def is_conflict(df, p, q):\n",
    "    is10 = False\n",
    "    is01 = False\n",
    "    is11 = False\n",
    "    for k in range(df.shape[0]):\n",
    "        if df.iloc[k, p] == 1 and df.iloc[k, q] == 0:\n",
    "            is10 = True\n",
    "        if df.iloc[k, p] == 0 and df.iloc[k, q] == 1:\n",
    "            is01 = True\n",
    "        if df.iloc[k, p] == 1 and df.iloc[k, q] == 1:\n",
    "            is11 = True\n",
    "    return is10 and is01 and is11\n",
    "\n",
    "# Get matrix of is_conflict\n",
    "def find_conflict_columns(X):\n",
    "    conflicts = []\n",
    "    for p in range(n):\n",
    "        temp = []\n",
    "        for q in range(n):\n",
    "            temp.append(is_conflict(X, p, q))\n",
    "        conflicts.append(temp)\n",
    "    conflicts = pd.DataFrame(conflicts)\n",
    "    return conflicts\n",
    "# TODO: Make this more efficient - how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the LP & find the lower bound\n",
    "# Input: SCS, ColSelector - which col pairs to add constraints for, verbose\n",
    "# Return: LP_objective, LP_solution (float)\n",
    "def solve_LP(SCS, ColSelector = None, verbose = False):\n",
    "    \n",
    "    solver = pywraplp.Solver.CreateSolver(\"GLOP\")\n",
    "    m = SCS.shape[0] # rows\n",
    "    n = SCS.shape[1] # cols\n",
    "\n",
    "    # Create variables\n",
    "    vars = {}\n",
    "    for p in range(n):\n",
    "        for q in range(p+1, n):\n",
    "            if ColSelector is None or ColSelector.iloc[p, q]: # Check cols\n",
    "                vars[f\"B_{p}_{q}_1_0\"] = solver.NumVar(0, 1, f\"B_{p}_{q}_1_0\") # (6)\n",
    "                vars[f\"B_{p}_{q}_0_1\"] = solver.NumVar(0, 1, f\"B_{p}_{q}_0_1\") # (6)\n",
    "                vars[f\"B_{p}_{q}_1_1\"] = solver.NumVar(0, 1, f\"B_{p}_{q}_1_1\") # (6)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            vars[f\"x_{i}_{j}\"] = solver.NumVar(float(SCS.iloc[i, j]), 1, f\"x_{i}_{j}\") # (7)\n",
    "    if verbose:\n",
    "        print(solver.NumVariables(), \"variables created\")\n",
    "\n",
    "    # Create constraints\n",
    "    for p in range(n):\n",
    "        for q in range(p+1, n):\n",
    "            if ColSelector is None or ColSelector.iloc[p, q]: # Check cols\n",
    "                solver.Add(vars[f\"B_{p}_{q}_1_0\"] + vars[f\"B_{p}_{q}_0_1\"] + vars[f\"B_{p}_{q}_1_1\"] <= 2) # (5)\n",
    "                for i in range(m):\n",
    "                    solver.Add(vars[f\"x_{i}_{p}\"] - vars[f\"x_{i}_{q}\"] <= vars[f\"B_{p}_{q}_1_0\"]) # (2)\n",
    "                    solver.Add(- vars[f\"x_{i}_{p}\"] + vars[f\"x_{i}_{q}\"] <= vars[f\"B_{p}_{q}_0_1\"]) # (3)\n",
    "                    solver.Add(vars[f\"x_{i}_{p}\"] + vars[f\"x_{i}_{q}\"] <= 1 + vars[f\"B_{p}_{q}_1_1\"]) # (4)\n",
    "    if verbose:\n",
    "        print(solver.NumConstraints(), \"constraints created\")\n",
    "\n",
    "    # Define objective function\n",
    "    objective = solver.Objective()\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if SCS.iloc[i, j] == 0: # only if they used to be 0\n",
    "                objective.SetCoefficient(vars[f\"x_{i}_{j}\"], 1) # (1)\n",
    "    objective.SetMinimization()\n",
    "\n",
    "    # Solve & print objective\n",
    "    status = solver.Solve()\n",
    "    if status != pywraplp.Solver.OPTIMAL:\n",
    "        print(\"The problem does not have an optimal solution.\")\n",
    "        exit(1)\n",
    "    objective_value = objective.Value()\n",
    "    if verbose:\n",
    "        print(f\"Solving with {solver.SolverVersion()}\\n\")\n",
    "        print(f\"Solution:\\nLower bound (LP objective) = {objective_value:0.5f}\")\n",
    "\n",
    "    # Create & print the solution DF\n",
    "    solution = []\n",
    "    for i in range(m):\n",
    "        solution.append([vars[f\"x_{i}_{j}\"].solution_value() for j in range(n)])\n",
    "    solution = pd.DataFrame(solution)\n",
    "    if verbose:\n",
    "        display(solution)\n",
    "\n",
    "    # Return\n",
    "    return objective_value, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SCS data\n",
    "# Input: SCS_array - list of SCS matrices, SCS_names - list of names\n",
    "# Return: Matrix of each difference - (row, col, mat1_val, mat2_val, ...)\n",
    "def compare_SCS(SCS_array, SCS_names):\n",
    "    m = SCS_array[0].shape[0]\n",
    "    n = SCS_array[0].shape[1]\n",
    "    diffs = []\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            to_add = False\n",
    "            temp = [i, j]\n",
    "            for SCS_DF in SCS_array:\n",
    "                if SCS_DF.iloc[i, j] != SCS_array[0].iloc[i, j]:\n",
    "                    to_add = True\n",
    "                temp.append(SCS_DF.iloc[i, j])\n",
    "            if to_add:\n",
    "                diffs.append(temp)\n",
    "    diffs = pd.DataFrame(diffs, columns=[\"row\", \"col\"] + SCS_names)\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from ortools.linear_solver import pywraplp\n",
    "from scphylo import datasets\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "from vc import vertex_cover_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/.pyenv/versions/phiscs/lib/python3.10/site-packages/anndata/__init__.py:52: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "DISPLAY_TABLES = False # Display the output tables\n",
    "READ_DATA = True # Read data from files\n",
    "REAL_DATA = datasets.melanoma20().X # Dataset to use (None if no dataset)\n",
    "FILE = \"./example/data2\" # File name without extension\n",
    "# If Read_Data is False, a None file will write to no file\n",
    "# If Read_Data is True (and ), FILE will be the file to read from (no extension)\n",
    "\n",
    "# For creating random data\n",
    "if not READ_DATA and REAL_DATA is None:\n",
    "    m = 200 # rows\n",
    "    n = 50 # cols\n",
    "    # Note: m and n get defined later in other cases\n",
    "\n",
    "exp_timers = {}  # track the experiments' durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Create data (Read_Data = False and )\n",
    "if not READ_DATA and REAL_DATA is None:\n",
    "    In_SCS = make_random_data(m, n, FILE)\n",
    "    print(\"Dimensions of the created data:\", In_SCS.shape)\n",
    "    if DISPLAY_TABLES:\n",
    "        display(In_SCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Get real data (Real_data exists)\n",
    "if not READ_DATA and REAL_DATA is not None:\n",
    "\n",
    "    # Other datasets: https://scphylo-tools.readthedocs.io/en/latest/api_reference.html#datasets-datasets\n",
    "    In_SCS = pd.DataFrame(REAL_DATA).astype(int)\n",
    "    In_SCS.columns = [f\"mut{i}\" for i in range(In_SCS.shape[1])]\n",
    "    m = In_SCS.shape[0] # rows\n",
    "    n = In_SCS.shape[1] # cols\n",
    "\n",
    "    # NOTE: LOTS OF COLS, LITTLE DATA\n",
    "\n",
    "    print(f\"Data shape: {In_SCS.shape}\")\n",
    "    if DISPLAY_TABLES:\n",
    "        display(In_SCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (50, 50)\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Read data (Read_Data = True)\n",
    "if READ_DATA:\n",
    "\n",
    "    In_SCS, CF_SCS, MutsAtEdges = read_data(FILE)\n",
    "    m = In_SCS.shape[0] # rows\n",
    "    n = In_SCS.shape[1] # cols\n",
    "    print(f\"Data shape: {In_SCS.shape}\")\n",
    "    if DISPLAY_TABLES:\n",
    "        print(\"\\nInput SCS data:\")\n",
    "        display(In_SCS)\n",
    "        print(\"Conflict-free SCS (answer) data:\")\n",
    "        display(CF_SCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cost of converting Input SCS to Conflict-Free SCS: 40\n",
      "\n",
      "Mutations (only false negative) between Input SCS and Conflict-Free SCS:\n"
     ]
    }
   ],
   "source": [
    "# Compare In_SCS and CF_SCS (if available)\n",
    "if READ_DATA:\n",
    "    real_cost = get_conversion_cost(In_SCS, CF_SCS)\n",
    "    print(f\"True cost of converting Input SCS to Conflict-Free SCS: {real_cost}\\n\")\n",
    "    print(\"Mutations (only false negative) between Input SCS and Conflict-Free SCS:\")\n",
    "    if DISPLAY_TABLES:\n",
    "        display(compare_SCS([In_SCS, CF_SCS], [\"In_SCS\", \"CF_SCS\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound (LP objective) with all columns: 34.0\n",
      "Lower bound (VC size / 2): 24\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Find the LP based lower bound (all columns)\n",
    "exp_timers['time_solve_lp_all_cols'] = time.time()\n",
    "LP_bound_all_columns, LP_solution_all_columns = solve_LP(In_SCS)\n",
    "exp_timers['time_solve_lp_all_cols'] = time.time() - exp_timers['time_solve_lp_all_cols']\n",
    "print(\"Lower bound (LP objective) with all columns:\", LP_bound_all_columns)\n",
    "\n",
    "# Tasks 1.2 Find the Vertex Cover based lower bound\n",
    "exp_timers['time_solve_vc'] = time.time()\n",
    "vc_lb, vc_flipped_bits = vertex_cover_pp(In_SCS.to_numpy())\n",
    "exp_timers['time_solve_vc'] = time.time() - exp_timers['time_solve_vc']\n",
    "print(f\"Lower bound (VC size / 2): {vc_lb}\")\n",
    "\n",
    "if DISPLAY_TABLES:\n",
    "    display(LP_solution_all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of converting rounded solution for LP with all columns to Input SCS: 50\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Deterministic rounding & compare\n",
    "RoundedLP_solution_all_columns = (LP_solution_all_columns.iloc[:, :] >= 0.5).astype(int)\n",
    "RoundedLP_cost_all_columns = get_conversion_cost(In_SCS, RoundedLP_solution_all_columns)\n",
    "print(f\"Cost of converting rounded solution for LP with all columns to Input SCS: {RoundedLP_cost_all_columns}\")\n",
    "if DISPLAY_TABLES:\n",
    "    display(compare_SCS([In_SCS, RoundedLP_solution_all_columns], [\"In_SCS\", \"Rounded All Columns\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Get the conflict columns - takes a long time\n",
    "exp_timers['time_solve_lp_conflict_cols_only'] = time.time()\n",
    "conflict_columns = find_conflict_columns(In_SCS)\n",
    "if DISPLAY_TABLES:\n",
    "    print(\"Conflict columns:\")\n",
    "    display(pd.DataFrame(conflict_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower bound (LP objective) with conflict columns: 34.0\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Find the LP based lower bound (conflict columns)\n",
    "LP_bound_conflict_columns, LP_solution_conflict_columns = solve_LP(In_SCS, conflict_columns)\n",
    "print(\"Lower bound (LP objective) with conflict columns:\", LP_bound_conflict_columns)\n",
    "if DISPLAY_TABLES:\n",
    "    display(LP_solution_conflict_columns)\n",
    "exp_timers['time_solve_lp_conflict_cols_only'] = time.time() - exp_timers['time_solve_lp_conflict_cols_only'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost of converting rounded solution for LP with conflict columns to Input SCS: 50\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Deterministic rounding & compare\n",
    "RoundedLP_solution_conflict_columns = (LP_solution_conflict_columns.iloc[:, :] >= 0.5).astype(int)\n",
    "RoundedLP_cost_conflict_columns = get_conversion_cost(In_SCS, RoundedLP_solution_conflict_columns)\n",
    "print(f\"Cost of converting rounded solution for LP with conflict columns to Input SCS: {RoundedLP_cost_conflict_columns}\")\n",
    "if DISPLAY_TABLES:\n",
    "    display(compare_SCS([In_SCS, RoundedLP_solution_conflict_columns], [\"In_SCS\", \"Rounded Conflict Columns\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True cost of converting Input SCS to Conflict-Free SCS: 40\n",
      "Lower bound (LP objective) with all columns: 34.0\n",
      "Lower bound (LP objective) with conflict columns: 34.0\n",
      "Cost of converting rounded solution for LP with all columns to Input SCS: 50\n",
      "Cost of converting rounded solution for LP with conflict columns to Input SCS: 50\n"
     ]
    }
   ],
   "source": [
    "# Compare costs\n",
    "if READ_DATA:\n",
    "    print(f\"True cost of converting Input SCS to Conflict-Free SCS: {real_cost}\")\n",
    "print(\"Lower bound (LP objective) with all columns:\", LP_bound_all_columns)\n",
    "print(\"Lower bound (LP objective) with conflict columns:\", LP_bound_conflict_columns)\n",
    "print(f\"Cost of converting rounded solution for LP with all columns to Input SCS: {RoundedLP_cost_all_columns}\")\n",
    "print(f\"Cost of converting rounded solution for LP with conflict columns to Input SCS: {RoundedLP_cost_conflict_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP (all columns) vs LP (conflict columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>LP_all_columns</th>\n",
       "      <th>LP_conflict_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row, col, LP_all_columns, LP_conflict_columns]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare LP (all columns) and LP (conflict columns)\n",
    "print(\"LP (all columns) vs LP (conflict columns):\")\n",
    "display(compare_SCS([LP_solution_all_columns, LP_solution_conflict_columns], [\"LP_all_columns\", \"LP_conflict_columns\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rounded LP (all columns) vs Rounded LP (conflict columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>RoundedLP_all_columns</th>\n",
       "      <th>RoundedLP_conflict_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row, col, RoundedLP_all_columns, RoundedLP_conflict_columns]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Rounded LP (all columns) and Rounded LP (conflict columns)\n",
    "print(\"Rounded LP (all columns) vs Rounded LP (conflict columns):\")\n",
    "display(compare_SCS([RoundedLP_solution_all_columns, RoundedLP_solution_conflict_columns],\n",
    "    [\"RoundedLP_all_columns\", \"RoundedLP_conflict_columns\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results to disk\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        'lp_obj_all_columns': [LP_bound_all_columns],\n",
    "        'lp_obj_conflict_columns_only': [LP_bound_conflict_columns],\n",
    "        'lp_sol_all_columns': [LP_solution_all_columns],\n",
    "        'lp_sol_conflict_columns_only': [LP_solution_conflict_columns],\n",
    "        'rounded_lp_obj_all_columns': [RoundedLP_cost_all_columns],\n",
    "        'rounded_lp_obj_conflict_columns_only': [RoundedLP_cost_conflict_columns],\n",
    "        'rounded_lp_sol_all_columns': [RoundedLP_solution_all_columns],\n",
    "        'rounded_lp_sol_conflict_columns_only': [RoundedLP_solution_conflict_columns],\n",
    "        'vc_lb': [vc_lb],\n",
    "        'vc_flipped_bits': [vc_flipped_bits],\n",
    "    } \n",
    "    | exp_timers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPS_DIR = 'results'\n",
    "write_time_str = str(datetime.datetime.now().replace(microsecond=0))\n",
    "CSV_PATH = os.path.join(EXPS_DIR, write_time_str + '.csv')\n",
    "\n",
    "if not os.path.exists(EXPS_DIR):\n",
    "    os.mkdir(EXPS_DIR)\n",
    "results.to_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    " - confernec\n",
    "\n",
    "mailto:farid.rashidimehrabadi@nih.gov - ask for data\n",
    "\n",
    "Make sure to CC Salem (and Cenk)\n",
    "\n",
    "Tree visualization\n",
    "\n",
    "incoporate mutsAtEdges\n",
    "\n",
    "Add the list of relevent data points to the driver section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phiscs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
